<!-- Generated by pkgdown: do not edit by hand -->
<!DOCTYPE html>
<html>
  <head>
  <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>
 — CV.SuperLearner • SuperLearner</title>

<!-- jquery -->
<script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script>
<!-- Bootstrap -->

<link href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>

<!-- Font Awesome icons -->
<link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">


<!-- pkgdown -->
<link href="../pkgdown.css" rel="stylesheet">
<script src="../jquery.sticky-kit.min.js"></script>
<script src="../pkgdown.js"></script>

<!-- mathjax -->
<script src='https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'></script>

<!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
  </head>

  <body>
    <div class="container template-reference-topic">
      <header>
      <div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="../index.html">SuperLearner</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="../reference/index.html">Reference</a>
</li>
<li>
  <a href="../articles/index.html">Articles</a>
</li>
      </ul>
      
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/ecpolley/SuperLearner">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

      
      </header>

      <div class="row">
  <div class="col-md-9 contents">
    <div class="page-header">
    <h1>
</h1>
    </div>

    
    <p>Function to get V-fold cross-validated risk estimate for super learner. This function simply splits the data into V folds and then calls SuperLearner. Most of the arguments are passed directly to SuperLearner.</p>
    

    <pre><span class='fu'>CV.SuperLearner</span>(<span class='no'>Y</span>, <span class='no'>X</span>, <span class='kw'>V</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>family</span> <span class='kw'>=</span> <span class='fu'>gaussian</span>(), <span class='no'>SL.library</span>,
  <span class='kw'>method</span> <span class='kw'>=</span> <span class='st'>"method.NNLS"</span>, <span class='kw'>id</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>verbose</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>,
  <span class='kw'>control</span> <span class='kw'>=</span> <span class='fu'>list</span>(<span class='kw'>saveFitLibrary</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>), <span class='kw'>cvControl</span> <span class='kw'>=</span> <span class='fu'>list</span>(),
  <span class='kw'>innerCvControl</span> <span class='kw'>=</span> <span class='fu'>list</span>(),
  <span class='kw'>obsWeights</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>saveAll</span> <span class='kw'>=</span> <span class='fl'>TRUE</span>, <span class='kw'>parallel</span> <span class='kw'>=</span> <span class='st'>"seq"</span>, <span class='kw'>env</span> <span class='kw'>=</span> <span class='fu'>parent.frame</span>())</pre>
    
    <h2 class="hasAnchor" id="arguments"><a class="anchor" href="#arguments"></a> Arguments</h2>
    <dl class="dl-horizontal">
      <dt>Y</dt>
      <dd>
The outcome.
</dd>
      <dt>X</dt>
      <dd>
The covariates.
</dd>
      <dt>V</dt>
      <dd>
The number of folds for <code>CV.SuperLearner</code>. This argument will be depreciated and moved into the <code>cvControl</code>. If Both <code>V</code> and <code>cvControl</code> set the number of cross-validation folds, an error message will appear. The recommendation is to use <code>cvControl</code>. This is not the number of folds for <code>SuperLearner</code>. The number of folds for <code>SuperLearner</code> is controlled with <code>innerCvControl</code>.
</dd>
      <dt>family</dt>
      <dd>
Currently allows <code>gaussian</code> or <code>binomial</code> to describe the error distribution. Link function information will be ignored and should be contained in the method argument below.
</dd>
      <dt>SL.library</dt>
      <dd>
Either a character vector of prediction algorithms or a list containing character vectors. See details below for examples on the structure. A list of functions included in the SuperLearner package can be found with <code>listWrappers()</code>.
</dd>
      <dt>method</dt>
      <dd>
A list (or a function to create a list) containing details on estimating the coefficients for the super learner and the model to combine the individual algorithms in the library. See <code>?method.template</code> for details.  Currently, the built in options are either &quot;method.NNLS&quot; (the default), &quot;method.NNLS2&quot;, &quot;method.NNloglik&quot;, &quot;method.CC_LS&quot;, &quot;method.CC_nloglik&quot;, or &quot;method.AUC&quot;.  NNLS and NNLS2 are non-negative least squares based on the Lawson-Hanson algorithm and the dual method of Goldfarb and Idnani, respectively.  NNLS and NNLS2 will work for both gaussian and binomial outcomes.  NNloglik is a non-negative binomial likelihood maximization using the BFGS quasi-Newton optimization method. NN* methods are normalized so weights sum to one. CC_LS uses Goldfarb and Idnani&#39;s quadratic programming algorithm to calculate the best convex combination of weights to minimize the squared error loss. CC_nloglik calculates the convex combination of weights that minimize the negative binomial log likelihood on the logistic scale using the sequential quadratic programming algorithm.  AUC, which only works for binary outcomes, uses the Nelder-Mead method via the optim function to minimize rank loss (equivalent to maximizing AUC).
</dd>
      <dt>id</dt>
      <dd>
Optional cluster identification variable. For the cross-validation splits, <code>id</code> forces observations in the same cluster to be in the same validation fold. <code>id</code> is passed to the prediction and screening algorithms in SL.library, but be sure to check the individual wrappers as many of them ignore the information.
</dd>
      <dt>verbose</dt>
      <dd>
Logical; TRUE for printing progress during the computation (helpful for debugging).
</dd>
      <dt>control</dt>
      <dd>
A list of parameters to control the estimation process. Parameters include <code>saveFitLibrary</code> and <code>trimLogit</code>. See <code><a href='SuperLearner.control.html'>SuperLearner.control</a></code> for details.
</dd>
      <dt>cvControl</dt>
      <dd>
A list of parameters to control the outer cross-validation process. The outer cross-validation is the sample spliting for evaluating the SuperLearner. Parameters include <code>V</code>, <code>stratifyCV</code>, <code>shuffle</code> and <code>validRows</code>. See <code><a href='SuperLearner.CV.control.html'>SuperLearner.CV.control</a></code> for details.
</dd>
      <dt>innerCvControl</dt>
      <dd>
A list of lists of parameters to control the inner cross-validation process. It should have <code>V</code> elements in the list, each a valid <code>cvControl</code> list. If only a single value, then replicated across all folds. The inner cross-validation are the values passed to each of the <code>V</code> <code>SuperLearner</code> calls. Parameters include <code>V</code>, <code>stratifyCV</code>, <code>shuffle</code> and <code>validRows</code>. See <code><a href='SuperLearner.CV.control.html'>SuperLearner.CV.control</a></code> for details.
</dd>
      <dt>obsWeights</dt>
      <dd>
Optional observation weights variable. As with <code>id</code> above, <code>obsWeights</code> is passed to the prediction and screening algorithms, but many of the built in wrappers ignore (or can&#39;t use) the information. If you are using observation weights, make sure the library you specify uses the information.
</dd>
      <dt>saveAll</dt>
      <dd>
Logical; Should the entire <code>SuperLearner</code> object be saved for each fold?
</dd>
      <dt>parallel</dt>
      <dd>
Options for parallel computation of the V-fold step. Use &quot;seq&quot; (the default) for sequential computation. <code>parallel = &#39;multicore&#39;</code> to use <code>mclapply</code> for the V-fold step (but note that <code>SuperLearner()</code> will still be sequential). The default for mclapply is to check the <code>mc.cores</code> option, and if not set to default to 2 cores. Be sure to set <code>options()$mc.cores</code> to the desired number of cores if you don&#39;t want the default. Or <code>parallel</code> can be the name of a snow cluster and will use <code>parLapply</code> for the V-fold step. For both multicore and snow, the inner <code>SuperLearner</code> calls will be sequential.
  </dd>
      <dt>env</dt>
      <dd>
  Environment containing the learner functions. Defaults to the calling environment.
  </dd>
    </dl>
    
    <h2 class="hasAnchor" id="details"><a class="anchor" href="#details"></a>Details</h2>

    <p>The <code>SuperLearner</code> function builds a estimator, but does not contain an estimate on the performance of the estimator. Various methods exist for estimator performance evaluation. If you are familiar with the super learner algorithm, it should be no surprise we recommend using cross-validation to evaluate the honest performance of the super learner estimator. The function <code>CV.SuperLearner</code> computes the usual V-fold cross-validated risk estimate for the super learner (and all algorithms in <code>SL.library</code> for comparison).</p>
    
    <h2 class="hasAnchor" id="value"><a class="anchor" href="#value"></a>Value</h2>

    <p>An object of class <code>CV.SuperLearner</code> (a list) with components:</p>
    
    <h2 class="hasAnchor" id="see-also"><a class="anchor" href="#see-also"></a>See also</h2>

    <p><code><a href='SuperLearner.html'>SuperLearner</a></code></p>
    

    <h2 class="hasAnchor" id="examples"><a class="anchor" href="#examples"></a>Examples</h2>
    <pre class="examples"><div class='input'><span class='co'>## Not run: ------------------------------------</span>
<span class='co'># set.seed(23432)</span>
<span class='co'># ## training set</span>
<span class='co'># n &lt;- 500</span>
<span class='co'># p &lt;- 50</span>
<span class='co'># X &lt;- matrix(rnorm(n*p), nrow = n, ncol = p)</span>
<span class='co'># colnames(X) &lt;- paste("X", 1:p, sep="")</span>
<span class='co'># X &lt;- data.frame(X)</span>
<span class='co'># Y &lt;- X[, 1] + sqrt(abs(X[, 2] * X[, 3])) + X[, 2] - X[, 3] + rnorm(n)</span>
<span class='co'># </span>
<span class='co'># ## build Library and run Super Learner</span>
<span class='co'># SL.library &lt;- c("SL.glm", "SL.randomForest", "SL.gam", "SL.polymars", "SL.mean")</span>
<span class='co'># </span>
<span class='co'># test &lt;- CV.SuperLearner(Y = Y, X = X, V = 10, SL.library = SL.library,</span>
<span class='co'>#   verbose = TRUE, method = "method.NNLS")</span>
<span class='co'># test</span>
<span class='co'># summary(test)</span>
<span class='co'># ## Look at the coefficients across folds</span>
<span class='co'># coef(test)</span>
<span class='co'># </span>
<span class='co'># # Example with specifying cross-validation options for both </span>
<span class='co'># # CV.SuperLearner (cvControl) and the internal SuperLearners (innerCvControl)</span>
<span class='co'># test &lt;- CV.SuperLearner(Y = Y, X = X, SL.library = SL.library,</span>
<span class='co'>#   cvControl = list(V = 10, shuffle = FALSE),</span>
<span class='co'>#   innerCvControl = list(list(V = 5)),</span>
<span class='co'>#   verbose = TRUE, method = "method.NNLS")</span>
<span class='co'># </span>
<span class='co'># ## examples with snow</span>
<span class='co'># library(parallel)</span>
<span class='co'># cl &lt;- makeCluster(2, type = "PSOCK") # can use different types here</span>
<span class='co'># clusterSetRNGStream(cl, iseed = 2343)</span>
<span class='co'># testSNOW &lt;- CV.SuperLearner(Y = Y, X = X, SL.library = SL.library, method = "method.NNLS",</span>
<span class='co'>#   parallel = cl)</span>
<span class='co'># summary(testSNOW)</span>
<span class='co'># stopCluster(cl)</span>
<span class='co'>## ---------------------------------------------</span></div></pre>
  </div>
  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
    <h2>Contents</h2>
    <ul class="nav nav-pills nav-stacked">
      <li><a href="#arguments">Arguments</a></li>
      
      <li><a href="#details">Details</a></li>

      <li><a href="#value">Value</a></li>

      <li><a href="#see-also">See also</a></li>
      
      <li><a href="#examples">Examples</a></li>
    </ul>

    <h2>Author</h2>
     Eric C Polley <a href='mailto:polley.eric@mayo.edu'>polley.eric@mayo.edu</a> 
  </div>
</div>

      <footer>
      <div class="copyright">
  <p>Developed by Eric Polley, Erin LeDell, Chris Kennedy, Mark van der Laan.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://hadley.github.io/pkgdown/">pkgdown</a>.</p>
</div>

      </footer>
   </div>

  </body>
</html>
