<!-- Generated by pkgdown: do not edit by hand -->
<!DOCTYPE html>
<html>
  <head>
  <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>Super Learner Prediction Function — SuperLearner • SuperLearner</title>

<!-- jquery -->
<script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script>
<!-- Bootstrap -->

<link href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>

<!-- Font Awesome icons -->
<link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">


<!-- pkgdown -->
<link href="../pkgdown.css" rel="stylesheet">
<script src="../jquery.sticky-kit.min.js"></script>
<script src="../pkgdown.js"></script>

<!-- mathjax -->
<script src='https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'></script>

<!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
  </head>

  <body>
    <div class="container template-reference-topic">
      <header>
      <div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="../index.html">SuperLearner</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="../reference/index.html">Reference</a>
</li>
<li>
  <a href="../articles/index.html">Articles</a>
</li>
      </ul>
      
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/ecpolley/SuperLearner">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

      
      </header>

      <div class="row">
  <div class="col-md-9 contents">
    <div class="page-header">
    <h1>Super Learner Prediction Function</h1>
    </div>

    
    <p>A Prediction Function for the Super Learner.  The <code>SuperLearner</code> function takes a training set pair (X,Y) and returns the predicted values based on a validation set.</p>
    

    <pre><span class='fu'>SuperLearner</span>(<span class='no'>Y</span>, <span class='no'>X</span>, <span class='kw'>newX</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>family</span> <span class='kw'>=</span> <span class='fu'>gaussian</span>(), <span class='no'>SL.library</span>,
  <span class='kw'>method</span> <span class='kw'>=</span> <span class='st'>"method.NNLS"</span>, <span class='kw'>id</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>verbose</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>,
  <span class='kw'>control</span> <span class='kw'>=</span> <span class='fu'>list</span>(), <span class='kw'>cvControl</span> <span class='kw'>=</span> <span class='fu'>list</span>(), <span class='kw'>obsWeights</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>env</span> <span class='kw'>=</span> <span class='fu'>parent.frame</span>())</pre>
    
    <h2 class="hasAnchor" id="arguments"><a class="anchor" href="#arguments"></a> Arguments</h2>
    <dl class="dl-horizontal">
      <dt>Y</dt>
      <dd>
The outcome in the training data set. Must be a numeric vector.
</dd>
      <dt>X</dt>
      <dd>
The predictor variables in the training data set, usually a data.frame.
</dd>
      <dt>newX</dt>
      <dd>
The predictor variables in the validation data set. The structure should match X. If missing, uses X for newX.
</dd>
      <dt>SL.library</dt>
      <dd>
Either a character vector of prediction algorithms or a list containing character vectors. See details below for examples on the structure. A list of functions included in the SuperLearner package can be found with <code>listWrappers()</code>.</dd>
      <dt>verbose</dt>
      <dd>
logical; TRUE for printing progress during the computation (helpful for debugging).
</dd>
      <dt>family</dt>
      <dd>
Currently allows <code>gaussian</code> or <code>binomial</code> to describe the error distribution. Link function information will be ignored and should be contained in the method argument below.
</dd>
      <dt>method</dt>
      <dd>
A list (or a function to create a list) containing details on estimating the coefficients for the super learner and the model to combine the individual algorithms in the library. See <code>?method.template</code> for details.  Currently, the built in options are either &quot;method.NNLS&quot; (the default), &quot;method.NNLS2&quot;, &quot;method.NNloglik&quot;, &quot;method.CC_LS&quot;, &quot;method.CC_nloglik&quot;, or &quot;method.AUC&quot;.  NNLS and NNLS2 are non-negative least squares based on the Lawson-Hanson algorithm and the dual method of Goldfarb and Idnani, respectively.  NNLS and NNLS2 will work for both gaussian and binomial outcomes.  NNloglik is a non-negative binomial likelihood maximization using the BFGS quasi-Newton optimization method. NN* methods are normalized so weights sum to one. CC_LS uses Goldfarb and Idnani&#39;s quadratic programming algorithm to calculate the best convex combination of weights to minimize the squared error loss. CC_nloglik calculates the convex combination of weights that minimize the negative binomial log likelihood on the logistic scale using the sequential quadratic programming algorithm.  AUC, which only works for binary outcomes, uses the Nelder-Mead method via the optim function to minimize rank loss (equivalent to maximizing AUC).
</dd>
      <dt>id</dt>
      <dd>
Optional cluster identification variable. For the cross-validation splits, <code>id</code> forces observations in the same cluster to be in the same validation fold. <code>id</code> is passed to the prediction and screening algorithms in SL.library, but be sure to check the individual wrappers as many of them ignore the information.
</dd>
      <dt>obsWeights</dt>
      <dd>
Optional observation weights variable. As with <code>id</code> above, <code>obsWeights</code> is passed to the prediction and screening algorithms, but many of the built in wrappers ignore (or can&#39;t use) the information. If you are using observation weights, make sure the library you specify uses the information.
</dd>
      <dt>control</dt>
      <dd>
A list of parameters to control the estimation process. Parameters include <code>saveFitLibrary</code> and <code>trimLogit</code>. See <code><a href='SuperLearner.control.html'>SuperLearner.control</a></code> for details.
</dd>
      <dt>cvControl</dt>
      <dd>
A list of parameters to control the cross-validation process. Parameters include <code>V</code>, <code>stratifyCV</code>, <code>shuffle</code> and <code>validRows</code>. See <code><a href='SuperLearner.CV.control.html'>SuperLearner.CV.control</a></code> for details.
</dd>
      <dt>env</dt>
      <dd>
  Environment containing the learner functions. Defaults to the calling environment.
  </dd>
    </dl>
    
    <h2 class="hasAnchor" id="details"><a class="anchor" href="#details"></a>Details</h2>

    <p><code>SuperLearner</code> fits the super learner prediction algorithm.  The weights for each algorithm in <code>SL.library</code> is estimated, along with the fit of each algorithm.</p>
    <p>The prescreen algorithms.  These algorithms first rank the variables in <code>X</code> based on either a univariate regression p-value of the <code>randomForest</code> variable importance.  A subset of the variables in <code>X</code> is selected based on a pre-defined cut-off.  With this subset of the X variables, the algorithms in <code>SL.library</code> are then fit.</p>
    <p>The SuperLearner package contains a few prediction and screening algorithm wrappers. The full list of wrappers can be viewed with <code>listWrappers()</code>. The design of the SuperLearner package is such that the user can easily add their own wrappers. We also maintain a website with additional examples of wrapper functions at <a href = 'https://github.com/ecpolley/SuperLearnerExtra'>https://github.com/ecpolley/SuperLearnerExtra</a>.</p>
    
    <h2 class="hasAnchor" id="value"><a class="anchor" href="#value"></a>Value</h2>

    <p></p>
    
    <h2 class="hasAnchor" id="references"><a class="anchor" href="#references"></a>References</h2>

    <p>van der Laan, M. J., Polley, E. C. and Hubbard, A. E. (2008) Super Learner, <em>Statistical Applications of Genetics and Molecular Biology</em>, <b>6</b>, article 25. <a href = 'http://www.bepress.com/sagmb/vol6/iss1/art25'>http://www.bepress.com/sagmb/vol6/iss1/art25</a></p>
    

    <h2 class="hasAnchor" id="examples"><a class="anchor" href="#examples"></a>Examples</h2>
    <pre class="examples"><div class='input'><span class='co'>## Not run: ------------------------------------</span>
<span class='co'># ## simulate data</span>
<span class='co'># set.seed(23432)</span>
<span class='co'># ## training set</span>
<span class='co'># n &lt;- 500</span>
<span class='co'># p &lt;- 50</span>
<span class='co'># X &lt;- matrix(rnorm(n*p), nrow = n, ncol = p)</span>
<span class='co'># colnames(X) &lt;- paste("X", 1:p, sep="")</span>
<span class='co'># X &lt;- data.frame(X)</span>
<span class='co'># Y &lt;- X[, 1] + sqrt(abs(X[, 2] * X[, 3])) + X[, 2] - X[, 3] + rnorm(n)</span>
<span class='co'># </span>
<span class='co'># ## test set</span>
<span class='co'># m &lt;- 1000</span>
<span class='co'># newX &lt;- matrix(rnorm(m*p), nrow = m, ncol = p)</span>
<span class='co'># colnames(newX) &lt;- paste("X", 1:p, sep="")</span>
<span class='co'># newX &lt;- data.frame(newX)</span>
<span class='co'># newY &lt;- newX[, 1] + sqrt(abs(newX[, 2] * newX[, 3])) + newX[, 2] -</span>
<span class='co'>#   newX[, 3] + rnorm(m)</span>
<span class='co'># </span>
<span class='co'># # generate Library and run Super Learner</span>
<span class='co'># SL.library &lt;- c("SL.glm", "SL.randomForest", "SL.gam",</span>
<span class='co'>#   "SL.polymars", "SL.mean")</span>
<span class='co'># test &lt;- SuperLearner(Y = Y, X = X, newX = newX, SL.library = SL.library,</span>
<span class='co'>#   verbose = TRUE, method = "method.NNLS")</span>
<span class='co'># test</span>
<span class='co'># </span>
<span class='co'># # library with screening</span>
<span class='co'># SL.library &lt;- list(c("SL.glmnet", "All"), c("SL.glm", "screen.randomForest",</span>
<span class='co'>#   "All", "screen.SIS"), "SL.randomForest", c("SL.polymars", "All"), "SL.mean")</span>
<span class='co'># test &lt;- SuperLearner(Y = Y, X = X, newX = newX, SL.library = SL.library,</span>
<span class='co'>#   verbose = TRUE, method = "method.NNLS")</span>
<span class='co'># test</span>
<span class='co'># </span>
<span class='co'># # binary outcome</span>
<span class='co'># set.seed(1)</span>
<span class='co'># N &lt;- 200</span>
<span class='co'># X &lt;- matrix(rnorm(N*10), N, 10)</span>
<span class='co'># X &lt;- as.data.frame(X)</span>
<span class='co'># Y &lt;- rbinom(N, 1, plogis(.2*X[, 1] + .1*X[, 2] - .2*X[, 3] +</span>
<span class='co'>#   .1*X[, 3]*X[, 4] - .2*abs(X[, 4])))</span>
<span class='co'># </span>
<span class='co'># SL.library &lt;- c("SL.glmnet", "SL.glm", "SL.knn", "SL.gam", "SL.mean")</span>
<span class='co'># </span>
<span class='co'># # least squares loss function</span>
<span class='co'># test.NNLS &lt;- SuperLearner(Y = Y, X = X, SL.library = SL.library,</span>
<span class='co'>#   verbose = TRUE, method = "method.NNLS", family = binomial())</span>
<span class='co'># test.NNLS</span>
<span class='co'># </span>
<span class='co'># # negative log binomial likelihood loss function</span>
<span class='co'># test.NNloglik &lt;- SuperLearner(Y = Y, X = X, SL.library = SL.library,</span>
<span class='co'>#   verbose = TRUE, method = "method.NNloglik", family = binomial())</span>
<span class='co'># test.NNloglik</span>
<span class='co'># </span>
<span class='co'># # 1 - AUC loss function</span>
<span class='co'># test.AUC &lt;- SuperLearner(Y = Y, X = X, SL.library = SL.library,</span>
<span class='co'>#   verbose = TRUE, method = "method.AUC", family = binomial())</span>
<span class='co'># test.AUC</span>
<span class='co'># </span>
<span class='co'># # 2</span>
<span class='co'># # adapted from library(SIS)</span>
<span class='co'># set.seed(1)</span>
<span class='co'># # training</span>
<span class='co'># b &lt;- c(2, 2, 2, -3*sqrt(2))</span>
<span class='co'># n &lt;- 150</span>
<span class='co'># p &lt;- 200</span>
<span class='co'># truerho &lt;- 0.5</span>
<span class='co'># corrmat &lt;- diag(rep(1-truerho, p)) + matrix(truerho, p, p)</span>
<span class='co'># corrmat[, 4] = sqrt(truerho)</span>
<span class='co'># corrmat[4, ] = sqrt(truerho)</span>
<span class='co'># corrmat[4, 4] = 1</span>
<span class='co'># cholmat &lt;- chol(corrmat)</span>
<span class='co'># x &lt;- matrix(rnorm(n*p, mean=0, sd=1), n, p)</span>
<span class='co'># x &lt;- x &lt;!-- %*% cholmat --&gt;</span>
<span class='co'># feta &lt;- x[, 1:4] &lt;!-- %*% b --&gt;</span>
<span class='co'># fprob &lt;- exp(feta) / (1 + exp(feta))</span>
<span class='co'># y &lt;- rbinom(n, 1, fprob)</span>
<span class='co'># </span>
<span class='co'># # test</span>
<span class='co'># m &lt;- 10000</span>
<span class='co'># newx &lt;- matrix(rnorm(m*p, mean=0, sd=1), m, p)</span>
<span class='co'># newx &lt;- newx &lt;!-- %*% cholmat --&gt;</span>
<span class='co'># newfeta &lt;- newx[, 1:4] &lt;!-- %*% b --&gt;</span>
<span class='co'># newfprob &lt;- exp(newfeta) / (1 + exp(newfeta))</span>
<span class='co'># newy &lt;- rbinom(m, 1, newfprob)</span>
<span class='co'># </span>
<span class='co'># DATA2 &lt;- data.frame(Y = y, X = x)</span>
<span class='co'># newDATA2 &lt;- data.frame(Y = newy, X=newx)</span>
<span class='co'># </span>
<span class='co'># create.SL.knn &lt;- function(k = c(20, 30)) {</span>
<span class='co'>#   for(mm in seq(length(k))){</span>
<span class='co'>#     eval(parse(text = paste('SL.knn.', k[mm], '&lt;- function(..., k = ', k[mm],</span>
<span class='co'>#       ') SL.knn(..., k = k)', sep = '')), envir = .GlobalEnv)</span>
<span class='co'>#   }</span>
<span class='co'>#   invisible(TRUE)</span>
<span class='co'># }</span>
<span class='co'># create.SL.knn(c(20, 30, 40, 50, 60, 70))</span>
<span class='co'># </span>
<span class='co'># # library with screening</span>
<span class='co'># SL.library &lt;- list(c("SL.glmnet", "All"), c("SL.glm", "screen.randomForest"),</span>
<span class='co'>#   "SL.randomForest", "SL.knn", "SL.knn.20", "SL.knn.30", "SL.knn.40",</span>
<span class='co'>#   "SL.knn.50", "SL.knn.60", "SL.knn.70",</span>
<span class='co'>#   c("SL.polymars", "screen.randomForest"))</span>
<span class='co'># test &lt;- SuperLearner(Y = DATA2$Y, X = DATA2[, -1], newX = newDATA2[, -1],</span>
<span class='co'>#   SL.library = SL.library, verbose = TRUE, family = binomial())</span>
<span class='co'># test</span>
<span class='co'># </span>
<span class='co'># ## examples with multicore</span>
<span class='co'># set.seed(23432, "L'Ecuyer-CMRG")  # use L'Ecuyer for multicore seeds. see ?set.seed for details</span>
<span class='co'># ## training set</span>
<span class='co'># n &lt;- 500</span>
<span class='co'># p &lt;- 50</span>
<span class='co'># X &lt;- matrix(rnorm(n*p), nrow = n, ncol = p)</span>
<span class='co'># colnames(X) &lt;- paste("X", 1:p, sep="")</span>
<span class='co'># X &lt;- data.frame(X)</span>
<span class='co'># Y &lt;- X[, 1] + sqrt(abs(X[, 2] * X[, 3])) + X[, 2] - X[, 3] + rnorm(n)</span>
<span class='co'># </span>
<span class='co'># ## test set</span>
<span class='co'># m &lt;- 1000</span>
<span class='co'># newX &lt;- matrix(rnorm(m*p), nrow = m, ncol = p)</span>
<span class='co'># colnames(newX) &lt;- paste("X", 1:p, sep="")</span>
<span class='co'># newX &lt;- data.frame(newX)</span>
<span class='co'># newY &lt;- newX[, 1] + sqrt(abs(newX[, 2] * newX[, 3])) + newX[, 2] - newX[, 3] + rnorm(m)</span>
<span class='co'># </span>
<span class='co'># # generate Library and run Super Learner</span>
<span class='co'># SL.library &lt;- c("SL.glm", "SL.randomForest", "SL.gam",</span>
<span class='co'>#   "SL.polymars", "SL.mean")</span>
<span class='co'># </span>
<span class='co'># testMC &lt;- mcSuperLearner(Y = Y, X = X, newX = newX, SL.library = SL.library,</span>
<span class='co'>#   method = "method.NNLS")</span>
<span class='co'># testMC</span>
<span class='co'># </span>
<span class='co'># ## examples with snow</span>
<span class='co'># library(parallel)</span>
<span class='co'># cl &lt;- makeCluster(2, type = "PSOCK") # can use different types here</span>
<span class='co'># clusterSetRNGStream(cl, iseed = 2343)</span>
<span class='co'># testSNOW &lt;- snowSuperLearner(cluster = cl, Y = Y, X = X, newX = newX,</span>
<span class='co'>#   SL.library = SL.library, method = "method.NNLS")</span>
<span class='co'># testSNOW</span>
<span class='co'># stopCluster(cl)</span>
<span class='co'># </span>
<span class='co'># ## snow example with user-generated wrappers</span>
<span class='co'># # If you write your own wrappers and are using snowSuperLearner()</span>
<span class='co'># # These new wrappers need to be added to the SuperLearner namespace and exported to the clusters</span>
<span class='co'># # Using a simple example here, but can define any new SuperLearner wrapper</span>
<span class='co'># my.SL.wrapper &lt;- function(...) SL.glm(...)</span>
<span class='co'># # assign function into SuperLearner namespace</span>
<span class='co'># environment(my.SL.wrapper) &lt;-asNamespace("SuperLearner")</span>
<span class='co'># </span>
<span class='co'># cl &lt;- makeCluster(2, type = "PSOCK") # can use different types here</span>
<span class='co'># clusterSetRNGStream(cl, iseed = 2343)</span>
<span class='co'># clusterExport(cl, c("my.SL.wrapper"))  # copy the function to all clusters</span>
<span class='co'># testSNOW &lt;- snowSuperLearner(cluster = cl, Y = Y, X = X, newX = newX,</span>
<span class='co'>#   SL.library = c("SL.glm", "SL.mean", "my.SL.wrapper"), method = "method.NNLS")</span>
<span class='co'># testSNOW</span>
<span class='co'># stopCluster(cl)</span>
<span class='co'># </span>
<span class='co'># ## timing</span>
<span class='co'># replicate(5, system.time(SuperLearner(Y = Y, X = X, newX = newX,</span>
<span class='co'>#   SL.library = SL.library, method = "method.NNLS")))</span>
<span class='co'># </span>
<span class='co'># replicate(5, system.time(mcSuperLearner(Y = Y, X = X, newX = newX,</span>
<span class='co'>#   SL.library = SL.library, method = "method.NNLS")))</span>
<span class='co'># </span>
<span class='co'># cl &lt;- makeCluster(2, type = 'PSOCK')</span>
<span class='co'># replicate(5, system.time(snowSuperLearner(cl, Y = Y, X = X, newX = newX,</span>
<span class='co'>#   SL.library = SL.library, method = "method.NNLS")))</span>
<span class='co'># stopCluster(cl)</span>
<span class='co'># </span>
<span class='co'>## ---------------------------------------------</span></div></pre>
  </div>
  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
    <h2>Contents</h2>
    <ul class="nav nav-pills nav-stacked">
      <li><a href="#arguments">Arguments</a></li>
      
      <li><a href="#details">Details</a></li>

      <li><a href="#value">Value</a></li>

      <li><a href="#references">References</a></li>
      
      <li><a href="#examples">Examples</a></li>
    </ul>

    <h2>Author</h2>
     Eric C Polley <a href='mailto:polley.eric@mayo.edu'>polley.eric@mayo.edu</a> 
  </div>
</div>

      <footer>
      <div class="copyright">
  <p>Developed by Eric Polley, Erin LeDell, Chris Kennedy, Mark van der Laan.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://hadley.github.io/pkgdown/">pkgdown</a>.</p>
</div>

      </footer>
   </div>

  </body>
</html>
