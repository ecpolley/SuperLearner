<!-- Generated by pkgdown: do not edit by hand -->
<!DOCTYPE html>
<html>
  <head>
  <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>Super Learner Prediction Function — SampleSplitSuperLearner • SuperLearner</title>

<!-- jquery -->
<script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script>
<!-- Bootstrap -->

<link href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>

<!-- Font Awesome icons -->
<link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">


<!-- pkgdown -->
<link href="../pkgdown.css" rel="stylesheet">
<script src="../jquery.sticky-kit.min.js"></script>
<script src="../pkgdown.js"></script>

<!-- mathjax -->
<script src='https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'></script>

<!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
  </head>

  <body>
    <div class="container template-reference-topic">
      <header>
      <div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="../index.html">SuperLearner</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="../reference/index.html">Reference</a>
</li>
<li>
  <a href="../articles/index.html">Articles</a>
</li>
      </ul>
      
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/ecpolley/SuperLearner">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

      
      </header>

      <div class="row">
  <div class="col-md-9 contents">
    <div class="page-header">
    <h1>Super Learner Prediction Function</h1>
    </div>

    
    <p>A Prediction Function for the Super Learner.  The <code>SuperLearner</code> function takes a training set pair (X,Y) and returns the predicted values based on a validation set. SampleSplitSuperLearner uses sample split validation whereas SuperLearner uses V-fold cross-validation.</p>
    

    <pre><span class='fu'>SampleSplitSuperLearner</span>(<span class='no'>Y</span>, <span class='no'>X</span>, <span class='kw'>newX</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>family</span> <span class='kw'>=</span> <span class='fu'>gaussian</span>(), <span class='no'>SL.library</span>,
  <span class='kw'>method</span> <span class='kw'>=</span> <span class='st'>"method.NNLS"</span>, <span class='kw'>id</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>verbose</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>,
  <span class='kw'>control</span> <span class='kw'>=</span> <span class='fu'>list</span>(), <span class='kw'>split</span> <span class='kw'>=</span> <span class='fl'>0.8</span>, <span class='kw'>obsWeights</span> <span class='kw'>=</span> <span class='kw'>NULL</span>)</pre>
    
    <h2 class="hasAnchor" id="arguments"><a class="anchor" href="#arguments"></a> Arguments</h2>
    <dl class="dl-horizontal">
      <dt>Y</dt>
      <dd> 
The outcome in the training data set. Must be a numeric vector.
</dd>
      <dt>X</dt>
      <dd>
The predictor variables in the training data set, usually a data.frame.
</dd>
      <dt>newX</dt>
      <dd>
The predictor variables in the validation data set. The structure should match X. If missing, uses X for newX.
</dd>
      <dt>SL.library</dt>
      <dd>
Either a character vector of prediction algorithms or a list containing character vectors. See details below for examples on the structure. A list of functions included in the SuperLearner package can be found with <code>listWrappers()</code>.</dd>
      <dt>verbose</dt>
      <dd>
logical; TRUE for printing progress during the computation (helpful for debugging).
</dd>
      <dt>family</dt>
      <dd> 
Currently allows <code>gaussian</code> or <code>binomial</code> to describe the error distribution. Link function information will be ignored and should be contained in the method argument below.
</dd>
      <dt>method</dt>
      <dd>
A list (or a function to create a list) containing details on estimating the coefficients for the super learner and the model to combine the individual algorithms in the library. See <code>?method.template</code> for details.  Currently, the built in options are either &quot;method.NNLS&quot; (the default), &quot;method.NNLS2&quot;, &quot;method.NNloglik&quot;, &quot;method.CC_LS&quot;, or &quot;method.CC_nloglik&quot;.  NNLS and NNLS2 are non-negative least squares based on the Lawson-Hanson algorithm and the dual method of Goldfarb and Idnani, respectively.  NNLS and NNLS2 will work for both gaussian and binomial outcomes.  NNloglik is a non-negative binomial likelihood maximization using the BFGS quasi-Newton optimization method. NN* methods are normalized so weights sum to one. CC_LS uses Goldfarb and Idnani&#39;s quadratic programming algorithm to calculate the best convex combination of weights to minimize the squared error loss. CC_nloglik calculates the convex combination of weights that minimize the negative binomial log likelihood on the logistic scale using the sequential quadratic programming algorithm. 
</dd>
      <dt>id</dt>
      <dd>
Optional cluster identification variable. For the cross-validation splits, <code>id</code> forces observations in the same cluster to be in the same validation fold. <code>id</code> is passed to the prediction and screening algorithms in SL.library, but be sure to check the individual wrappers as many of them ignore the information.
</dd>
      <dt>obsWeights</dt>
      <dd>
Optional observation weights variable. As with <code>id</code> above, <code>obsWeights</code> is passed to the prediction and screening algorithms, but many of the built in wrappers ignore (or can&#39;t use) the information. If you are using observation weights, make sure the library you specify uses the information.
</dd>
      <dt>control</dt>
      <dd>
A list of parameters to control the estimation process. Parameters include <code>saveFitLibrary</code> and <code>trimLogit</code>. See <code><a href='SuperLearner.control.html'>SuperLearner.control</a></code> for details.
</dd>
      <dt>split</dt>
      <dd>
Either a single value between 0 and 1 indicating the fraction of the samples for the training split. A value of 0.8 will randomly assign 80 percent of the samples to the training split and the other 20 percent to the validation split. Alternatively, split can be a numeric vector with the row numbers of <code>X</code> corresponding to the validation split. All other rows not in the vector will be considered in the training split.
</dd>
    </dl>
    
    <h2 class="hasAnchor" id="details"><a class="anchor" href="#details"></a>Details</h2>

    <p><code>SuperLearner</code> fits the super learner prediction algorithm.  The weights for each algorithm in <code>SL.library</code> is estimated, along with the fit of each algorithm.</p>
    <p>The prescreen algorithms.  These algorithms first rank the variables in <code>X</code> based on either a univariate regression p-value of the <code>randomForest</code> variable importance.  A subset of the variables in <code>X</code> is selected based on a pre-defined cut-off.  With this subset of the X variables, the algorithms in <code>SL.library</code> are then fit.</p>
    <p>The SuperLearner package contains a few prediction and screening algorithm wrappers. The full list of wrappers can be viewed with <code>listWrappers()</code>. The design of the SuperLearner package is such that the user can easily add their own wrappers. We also maintain a website with additional examples of wrapper functions at <a href = 'https://github.com/ecpolley/SuperLearnerExtra'>https://github.com/ecpolley/SuperLearnerExtra</a>.</p>
    
    <h2 class="hasAnchor" id="value"><a class="anchor" href="#value"></a>Value</h2>

    <p></p>
    
    <h2 class="hasAnchor" id="references"><a class="anchor" href="#references"></a>References</h2>

    <p>van der Laan, M. J., Polley, E. C. and Hubbard, A. E. (2008) Super Learner, <em>Statistical Applications of Genetics and Molecular Biology</em>, <b>6</b>, article 25. <a href = 'http://www.bepress.com/sagmb/vol6/iss1/art25'>http://www.bepress.com/sagmb/vol6/iss1/art25</a></p>
    

    <h2 class="hasAnchor" id="examples"><a class="anchor" href="#examples"></a>Examples</h2>
    <pre class="examples"><div class='input'><span class='co'>## Not run: ------------------------------------</span>
<span class='co'># ## simulate data</span>
<span class='co'># set.seed(23432)</span>
<span class='co'># ## training set</span>
<span class='co'># n &lt;- 500</span>
<span class='co'># p &lt;- 50</span>
<span class='co'># X &lt;- matrix(rnorm(n*p), nrow = n, ncol = p)</span>
<span class='co'># colnames(X) &lt;- paste("X", 1:p, sep="")</span>
<span class='co'># X &lt;- data.frame(X)</span>
<span class='co'># Y &lt;- X[, 1] + sqrt(abs(X[, 2] * X[, 3])) + X[, 2] - X[, 3] + rnorm(n)</span>
<span class='co'># </span>
<span class='co'># ## test set</span>
<span class='co'># m &lt;- 1000</span>
<span class='co'># newX &lt;- matrix(rnorm(m*p), nrow = m, ncol = p)</span>
<span class='co'># colnames(newX) &lt;- paste("X", 1:p, sep="")</span>
<span class='co'># newX &lt;- data.frame(newX)</span>
<span class='co'># newY &lt;- newX[, 1] + sqrt(abs(newX[, 2] * newX[, 3])) + newX[, 2] -</span>
<span class='co'>#   newX[, 3] + rnorm(m)</span>
<span class='co'># </span>
<span class='co'># # generate Library and run Super Learner</span>
<span class='co'># SL.library &lt;- c("SL.glm", "SL.randomForest", "SL.gam",</span>
<span class='co'>#   "SL.polymars", "SL.mean")</span>
<span class='co'># test &lt;- SampleSplitSuperLearner(Y = Y, X = X, newX = newX, SL.library = SL.library,</span>
<span class='co'>#   verbose = TRUE, method = "method.NNLS")</span>
<span class='co'># test</span>
<span class='co'># </span>
<span class='co'># # library with screening</span>
<span class='co'># SL.library &lt;- list(c("SL.glmnet", "All"), c("SL.glm", "screen.randomForest",</span>
<span class='co'>#   "All", "screen.SIS"), "SL.randomForest", c("SL.polymars", "All"), "SL.mean")</span>
<span class='co'># test &lt;- SuperLearner(Y = Y, X = X, newX = newX, SL.library = SL.library,</span>
<span class='co'>#   verbose = TRUE, method = "method.NNLS")</span>
<span class='co'># test</span>
<span class='co'># </span>
<span class='co'># # binary outcome</span>
<span class='co'># set.seed(1)</span>
<span class='co'># N &lt;- 200</span>
<span class='co'># X &lt;- matrix(rnorm(N*10), N, 10)</span>
<span class='co'># X &lt;- as.data.frame(X)</span>
<span class='co'># Y &lt;- rbinom(N, 1, plogis(.2*X[, 1] + .1*X[, 2] - .2*X[, 3] + </span>
<span class='co'>#   .1*X[, 3]*X[, 4] - .2*abs(X[, 4])))</span>
<span class='co'># </span>
<span class='co'># SL.library &lt;- c("SL.glmnet", "SL.glm", "SL.knn", "SL.gam", "SL.mean")</span>
<span class='co'># </span>
<span class='co'># # least squares loss function</span>
<span class='co'># test.NNLS &lt;- SampleSplitSuperLearner(Y = Y, X = X, SL.library = SL.library, </span>
<span class='co'>#   verbose = TRUE, method = "method.NNLS", family = binomial())</span>
<span class='co'># test.NNLS</span>
<span class='co'>## ---------------------------------------------</span></div></pre>
  </div>
  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
    <h2>Contents</h2>
    <ul class="nav nav-pills nav-stacked">
      <li><a href="#arguments">Arguments</a></li>
      
      <li><a href="#details">Details</a></li>

      <li><a href="#value">Value</a></li>

      <li><a href="#references">References</a></li>
      
      <li><a href="#examples">Examples</a></li>
    </ul>

    <h2>Author</h2>
     Eric C Polley <a href='mailto:polley.eric@mayo.edu'>polley.eric@mayo.edu</a> 
  </div>
</div>

      <footer>
      <div class="copyright">
  <p>Developed by Eric Polley, Erin LeDell, Chris Kennedy, Mark van der Laan.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://hadley.github.io/pkgdown/">pkgdown</a>.</p>
</div>

      </footer>
   </div>

  </body>
</html>
